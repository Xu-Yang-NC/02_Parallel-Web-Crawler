# Parallel-Web-Crawler

Refactor the pre-existing single-threaded web crawler to improve its performance by using the following technics:
 - Use software design patterns to extend the pre-existing web crawler.
 - Implement a multi-threaded web crawler that can process multiple web pages in parallel and track popular terms encountered by the crawler.
 - Use file IO to parse a JSON file that determines the web crawler's configuration when it runs.
 - Store the results of the web crawler to a file.
 - Use dependency injection and Aspect-Oriented Programming to write a method profiler that measures the performance of the multi-threaded crawler.
